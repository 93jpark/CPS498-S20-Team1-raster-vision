import torch
import torch.nn as nn
from torchvision.models.detection import maskrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
from rastervision.backend.torch_utils.object_detection.boxlist import BoxList


def get_out_channels(model):
    out = {}

    def make_save_output(layer_name):
        def save_output(layer, input, output):
            out[layer_name] = output.shape[1]

        return save_output

    model.layer1.register_forward_hook(make_save_output('layer1'))
    model.layer2.register_forward_hook(make_save_output('layer2'))
    model.layer3.register_forward_hook(make_save_output('layer3'))
    model.layer4.register_forward_hook(make_save_output('layer4'))

    model(torch.empty((1, 3, 128, 128)))
    return [out['layer1'], out['layer2'], out['layer3'], out['layer4']]


def get_model(num_classes=91, pretrained=False):

    if pretrained or num_classes == 91:
        assert num_classes == 91
        model = maskrcnn_resnet50_fpn(pretrained=True)

    elif num_classes != 91:

        # TODO: specify user options for hyper-parameters
        model = maskrcnn_resnet50_fpn(pretrained=True)

        # freeze/unfreeze layers
        unfreeze_heads = ['cls_score', 'bbox_pred', 'mask_fcn_logits']
        unfreeze_layers = ['layer2', 'layer3', 'layer4', 'fpn']

        for name, parameter in model.named_parameters():
            if any(unf in name for unf in unfreeze_layers):
                parameter.requires_grad_(True)
                # print('grad', name)
            elif any(unf in name for unf in unfreeze_heads):
                parameter.requires_grad_(True)
                # print('grad', name)
            else:
                parameter.requires_grad_(False)
                # print('no grad', name)

        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
        in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels

        hidden_layer = 256
        model.roi_heads.mask_predictor = MaskRCNNPredictor(in_channels=in_features_mask,
                                                           dim_reduced=hidden_layer,
                                                           num_classes=num_classes)
    else:
        raise NotImplementedError

    return model


# implement lewfish's approach to inject bogus boxes in negative training examples
# MyMaskRCNN
class MyMaskRCNN(nn.Module):
    """Adapter around torchvision Faster-RCNN.

    The purpose of the adapter is to use a different input and output format
    and inject bogus boxes to circumvent torchvision's inability to handle
    training examples with no ground truth boxes.
    """

    def __init__(self, num_labels, pretrained=True):
        super().__init__()

        self.model = get_model(num_classes=num_labels, pretrained=pretrained)

        self.subloss_names = [
            'total_loss', 'loss_box_reg', 'loss_classifier', 'loss_objectness',
            'loss_rpn_box_reg'
        ]

    def forward(self, input, targets=None, device=None):
        """Forward pass

        Args:
            input: tensor<n, 3, h, w> with batch of images
            targets: None or list<BoxList> of length n with boxes and labels

        Returns:
            if targets is None, returns list<BoxList> of length n, containing
            boxes, labels, and scores for boxes with score > 0.05. Further
            filtering based on score should be done before considering the
            prediction "final".

            if targets is a list, returns the losses as dict with keys from
            self.subloss_names.
        """
        if targets:
            # Add bogus background class box for each image to workaround
            # the inability of torchvision to train on images with
            # no ground truth boxes. This is important for being able
            # to handle negative chips generated by RV.
            new_targets = []
            for x, y in zip(input, targets):
                h, w = x.shape[1:]
                boxes = torch.cat(
                    [
                        y['boxes'],
                        torch.tensor([[0., 0, h, w]], device=device)
                    ],
                    dim=0)
                labels = torch.cat(
                    [
                        y['labels'],
                        torch.tensor([0], device=device)
                    ],
                    dim=0)
                bl = BoxList(boxes, labels=labels)
                new_targets.append(bl)
            targets = new_targets

            _targets = [bl.xyxy() for bl in targets]
            _targets = [{
                'boxes': bl.boxes,
                'labels': bl.get_field('labels')
            } for bl in _targets]
            loss_dict = self.model(input, _targets)
            loss_dict['total_loss'] = sum(list(loss_dict.values()))
            return loss_dict

        out = self.model(input)
        boxlists = [
            BoxList(
                _out['boxes'], labels=_out['labels'],
                scores=_out['scores']).yxyx() for _out in out
        ]

        # Remove bogus background boxes.
        new_boxlists = []
        for bl in boxlists:
            labels = bl.get_field('labels')
            non_zero_inds = labels != 0
            new_boxlists.append(bl.ind_filter(non_zero_inds))
        return new_boxlists


if __name__ == '__main__':
    get_model(num_classes=2, pretrained=False)
